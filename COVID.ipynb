{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Steps\n",
    "\n",
    "## Import models\n",
    "## Load Image and Preprocess Image\n",
    "## Split the data into train and test\n",
    "## Build the model\n",
    "## Finding accuracy\n",
    "## Prediction\n",
    "## Visulizing the model\n",
    "## Save the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pa\n",
    "import cv2\n",
    "import gc\n",
    "import os\n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import AveragePooling2D,MaxPooling2D,Dropout,Flatten,Dense,Input\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from imutils import paths\n",
    "import tensorflow as tf\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16177600225417982470,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5077532672\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 978556890862680438\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:25:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPipeLine:\n",
    "    def __init__(self,path=None):\n",
    "        self.path = path\n",
    "    \n",
    "    def test_image_preprocess(self,path):\n",
    "        self.path = path\n",
    "        images,labels,label_encoder = self.__load_image()\n",
    "        return images,labels,label_encoder\n",
    "    \n",
    "    def __load_image(self):\n",
    "        all_images = []\n",
    "        labels = []\n",
    "        \n",
    "        all_images_files = list(paths.list_images(self.path))\n",
    "        #print(all_images_files)\n",
    "        for image_file in all_images_files:\n",
    "            try:\n",
    "                image = cv2.imread(image_file)\n",
    "                image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image,(256,256))\n",
    "                all_images.append(image)\n",
    "\n",
    "                label = image_file.split(os.path.sep)[-2]\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                print(\"ERROR LOADING IMAGE\")\n",
    "        \n",
    "        all_images = np.array(all_images)/255.0\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        #print(all_images)\n",
    "        #print(labels)\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        encoded_label = label_encoder.fit_transform(labels)\n",
    "        labels = to_categorical(encoded_label)\n",
    "        \n",
    "        return all_images,labels,label_encoder\n",
    "    \n",
    "    def train_inceptionv3(self):\n",
    "        \n",
    "        lr = 1e-5  \n",
    "        epochs = 50 \n",
    "        batchsize = 8\n",
    "        \n",
    "        images,labels,_ = self.__load_image()\n",
    "        \n",
    "        (trainX,testX,trainY,testY) = train_test_split(images,labels,test_size=0.20,stratify=labels,random_state=42)\n",
    "        \n",
    "        ## Load the inceptionV3 model\n",
    "        basemodel = InceptionV3(weights='imagenet',include_top=False,input_tensor=Input(shape=(256,256,3)))\n",
    "        headmodel = basemodel.output\n",
    "        headmodel = MaxPooling2D(pool_size=(4, 4))(headmodel)\n",
    "        #headmodel = AveragePooling2D(pool_size=(4, 4))(headmodel)\n",
    "        headmodel = Flatten(name=\"flatten\")(headmodel)\n",
    "        headmodel = Dense(128, activation=\"relu\")(headmodel)\n",
    "        headmodel = Dropout(0.5)(headmodel)\n",
    "        headmodel = Dense(3, activation=\"softmax\")(headmodel)\n",
    "\n",
    "        model = Model(inputs=basemodel.input,outputs=headmodel)\n",
    "\n",
    "        opt = Adam(lr=lr, decay=lr / epochs)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "        model.summary()\n",
    "        \n",
    "        trainaugment =  ImageDataGenerator(rotation_range=15, fill_mode=\"nearest\")\n",
    "        \n",
    "        H = model.fit_generator( trainaugment.flow(trainX, trainY, batch_size=batchsize), steps_per_epoch=len(trainX) // batchsize,\n",
    "                         validation_data=(testX, testY), validation_steps=len(testX) // batchsize, epochs=epochs)\n",
    "        \n",
    "        self.__save_model(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Not Yet Completed\n",
    "    def train_vgg19(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def stackiing_classifier_dl(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def train_restnet50(self):\n",
    "        pass\n",
    "    \n",
    "    def __save_model(self,model):\n",
    "        model.save('D:/Models/covid_model_final.h5')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/BABI/Covid19-X-Rays-master/all/train\"\n",
    "train_1 = ModelPipeLine(path)\n",
    "train_1.train_inceptionv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('D:/Models/covid_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for checking the test dataset accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model:\n",
    "    def __init__(self,path):\n",
    "        BS = 8\n",
    "        test_obj = ModelPipeLine()\n",
    "        test_images,labels_test,label_encoder = test_obj.test_image_preprocess(path)\n",
    "        \n",
    "        predTest = model.predict(test_images, batch_size=BS)\n",
    "        print(predTest)\n",
    "        predClasses = predTest.argmax(axis=-1)\n",
    "        print(predClasses)\n",
    "        print(\"Evaluating real test samples ...\")\n",
    "\n",
    "        testX = test_images\n",
    "        testY = labels_test\n",
    "\n",
    "        predIdxs = model.predict(testX, batch_size=BS)\n",
    "        predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "\n",
    "        print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "            target_names=label_encoder.classes_))\n",
    "\n",
    "        cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
    "        total = sum(sum(cm))\n",
    "        acc = (cm[0, 0] + cm[1, 1] + cm[2, 2]) / total\n",
    "        sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1] + cm[0, 2])\n",
    "        specificity = (cm[1, 1] + cm[1, 2] + cm[2, 1] + cm[2, 2]) / (cm[1, 0] + cm[1, 1] + cm[1, 2] + cm[2, 0] + cm[2, 1] + cm[2, 2])\n",
    "\n",
    "        print(cm)\n",
    "        print(\"acc: {:.4f}\".format(acc))\n",
    "        print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "        print(\"specificity: {:.4f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.7659063e-01 2.2820769e-02 5.8865314e-04]\n",
      " [9.9840420e-01 2.9527312e-04 1.3004891e-03]\n",
      " [9.9273819e-01 3.8089780e-03 3.4527865e-03]\n",
      " [4.0290105e-01 2.1799172e-03 5.9491909e-01]\n",
      " [9.9883395e-01 8.1448967e-04 3.5162823e-04]\n",
      " [9.9955517e-01 1.0432238e-04 3.4043696e-04]\n",
      " [9.9432290e-01 2.4692898e-03 3.2078174e-03]\n",
      " [9.9891698e-01 5.1982304e-05 1.0309705e-03]\n",
      " [9.9450928e-01 8.8259956e-04 4.6081496e-03]\n",
      " [1.0585950e-03 9.8656625e-01 1.2375197e-02]\n",
      " [1.4145529e-02 7.8911167e-01 1.9674285e-01]\n",
      " [6.3940405e-04 2.2523463e-01 7.7412593e-01]\n",
      " [1.7382699e-04 9.9591488e-01 3.9112777e-03]\n",
      " [1.0733237e-04 9.4475830e-01 5.5134412e-02]\n",
      " [2.9796815e-02 7.2831142e-01 2.4189174e-01]\n",
      " [1.8055111e-05 9.4480848e-01 5.5173505e-02]\n",
      " [1.6443661e-05 9.9771297e-01 2.2705686e-03]\n",
      " [8.5260933e-03 9.7560674e-01 1.5867261e-02]\n",
      " [2.6607955e-05 4.2202327e-04 9.9955136e-01]\n",
      " [6.0503711e-03 7.1785448e-04 9.9323177e-01]\n",
      " [2.2053523e-02 3.7031441e-03 9.7424328e-01]\n",
      " [4.6245628e-03 2.3133113e-04 9.9514413e-01]\n",
      " [2.5476908e-02 1.0076477e-01 8.7375838e-01]\n",
      " [3.7536395e-04 7.1151915e-04 9.9891317e-01]\n",
      " [5.1050261e-04 4.6955323e-04 9.9901998e-01]\n",
      " [1.4651819e-01 3.9694592e-02 8.1378722e-01]\n",
      " [3.6901646e-04 2.1552853e-04 9.9941552e-01]]\n",
      "[0 0 0 2 0 0 0 0 0 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2]\n",
      "Evaluating real test samples ...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        covid       1.00      0.89      0.94         9\n",
      "       normal       1.00      0.89      0.94         9\n",
      "pneumonia_bac       0.82      1.00      0.90         9\n",
      "\n",
      "     accuracy                           0.93        27\n",
      "    macro avg       0.94      0.93      0.93        27\n",
      " weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "[[8 0 1]\n",
      " [0 8 1]\n",
      " [0 0 9]]\n",
      "acc: 0.9259\n",
      "sensitivity: 0.8889\n",
      "specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_ = Test_Model('C:/Users/BABI/Covid19-X-Rays-master/all/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Visualization (GRAD CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Visuals:\n",
    "    def __init__(self,image_path,GRAD_CAM = True):\n",
    "        file = image_path\n",
    "        self.image_original = cv2.imread(file)\n",
    "        plt.imshow(self.image_original)\n",
    "        plt.show()\n",
    "        \n",
    "        self.orig = cv2.cvtColor(self.image_original, cv2.COLOR_BGR2RGB)\n",
    "        resized = cv2.resize(self.orig, (256, 256))\n",
    "        dataXG = np.array(resized) / 255.0\n",
    "        dataXG = np.expand_dims(dataXG, axis=0)\n",
    "        \n",
    "        preds = model.predict(dataXG)\n",
    "        i = np.argmax(preds[0])\n",
    "        print(i, preds)\n",
    "        \n",
    "        if GRAD_CAM == True:\n",
    "            self.grad_cam_visulaization(dataXG,i)\n",
    "        \n",
    "    def grad_cam_visulaization(self,dataXG,i):\n",
    "        cam = GradCAM(model=model, classIdx=i, layerName='mixed10')\n",
    "        heatmap = cam.compute_heatmap(dataXG)\n",
    "        plt.imshow(heatmap)\n",
    "        plt.show()\n",
    "        \n",
    "        heatmapY = cv2.resize(heatmap, (self.orig.shape[1], self.orig.shape[0]))\n",
    "        heatmapY = cv2.applyColorMap(heatmapY, cv2.COLORMAP_HOT)  # COLORMAP_JET, COLORMAP_VIRIDIS, COLORMAP_HOT\n",
    "        imageY = cv2.addWeighted(heatmapY, 0.5, self.image_original, 1.0, 0)\n",
    "        print(heatmapY.shape, self.orig.shape)# draw the orignal x-ray, the heatmap, and the overlay together\n",
    "        #output = np.hstack([self.orig, heatmapY, imageY])\n",
    "        #fig, ax = plt.subplots(figsize=(20, 18))\n",
    "        #ax.imshow(np.random.rand(1, 99), interpolation='nearest')\n",
    "        plt.imshow(imageY)\n",
    "        plt.show()\n",
    "    \n",
    "    ## Soon\n",
    "    def grad_cam_plusplus_visulaization(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "            \n",
    "    def find_target_layer(self):\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if len(layer.output_shape) == 4:\n",
    "                return layer.name\n",
    "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
    "        \n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        \n",
    "        gradModel = Model(\n",
    "            inputs=[self.model.inputs],\n",
    "            outputs=[self.model.get_layer(self.layerName).output,\n",
    "                self.model.output])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = gradModel(inputs)\n",
    "            loss = predictions[:, self.classIdx]\n",
    "            \n",
    "        \n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "        \n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf_gpu_2': conda)",
   "language": "python",
   "name": "python37764bittfgpu2conda6869594dd3c349e79f9a3c302d5f44f6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
